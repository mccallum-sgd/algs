1)
N			Avg Time (ns)
100			----20161
1,000		----67213
10,000		--3791545
100,000		-49588753
1,000,000	109549282
--------------------------------------------------------------
What are reasonable values of "small" and "large" values of N?
--------------------------------------------------------------
This is a pretty ambiguous question but I'll take a stab at it.
A reasonable small value of N would be 10,000 I would say, still
extremely fast and pretty practical for most data-sets. If you're
working with very large databases then 100,000 would probably be 
the limit. 50ms is  about what you want to have to take with an 
algorithm in real-world applications and making clients wait any 
more than that is not ideal.

2)
MinSort construction
N			Time (ns)
1000		001313582
1000000		037154824
1000000000	OutOfMemory

MinSort removal
N			Time (ns)
1000		2357732
1000000		193367219
1000000000	OutOfMemory

--------------------------------------------------------
Do these agree with the expected rate of runtime growth?
--------------------------------------------------------
Yes, I would say it's linear. I plotted the 
runtimes and N's on my calculator and the graph is 
basically linear.

HeapSort construction
N			Time (ns)
1000		---415605
1000000		-30677382
1000000000	OutOfMemory

HeapSort repair
N			Time (ns)
1000		---918915
1000000		198832511
1000000000	OutOfMemory
